{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 5.1 Data Generation\n",
        "\n",
        "This notebook documents the two synthetic data generation pipelines used in the project:\n",
        "\n",
        "- **Method A:** SDXL Turbo (text-to-image) for generating full Zoom-like webcam images.\n",
        "- **Method B:** Inpainting background replacement using Stable Diffusion Inpainting + person segmentation mask.\n"
      ],
      "metadata": {
        "id": "8tOH9z65OnDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output structure (recommended)\n",
        "- `data/synthetic/sdxl_turbo/images/`\n",
        "- `data/synthetic/sdxl_turbo/labels.csv`\n",
        "\n",
        "- `data/synthetic/inpainting_bg_replace/images/`\n",
        "- `data/synthetic/inpainting_bg_replace/labels.csv`\n"
      ],
      "metadata": {
        "id": "_yAqIOY5Oszg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwSWC_7XOmHl"
      },
      "outputs": [],
      "source": [
        "# Optional (Colab): install dependencies if you want to run the notebook.\n",
        "# !pip install -q diffusers transformers accelerate torch pillow pandas\n",
        "# !pip install -q mediapipe==0.10.13 opencv-python-headless"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method A: SDXL Turbo (Text-to-Image)\n",
        "\n",
        "Generates full synthetic Zoom-like webcam images from a randomly sampled behavior vector:\n",
        "`gaze, headphones, location, privacy, object`.\n",
        "\n",
        "**Key idea:** prompt is built directly from the behavior vector, and the vector is saved to `labels.csv`.\n"
      ],
      "metadata": {
        "id": "KIAa6KTjROW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "import pandas as pd\n",
        "\n",
        "METHOD_A_BASE = \"data/synthetic/sdxl_turbo\"\n",
        "METHOD_A_IMAGES = os.path.join(METHOD_A_BASE, \"images\")\n",
        "METHOD_A_LABELS = os.path.join(METHOD_A_BASE, \"labels.csv\")\n",
        "\n",
        "os.makedirs(METHOD_A_IMAGES, exist_ok=True)\n",
        "\n",
        "NUM_IMAGES_TO_GENERATE = 1000\n",
        "IMAGE_SIZE = 512\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "4vFuG2stRSm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GAZE_OPTIONS = {\n",
        "    \"looking_at_camera\": \"eyes looking at camera\",\n",
        "    \"looking_away\": \"eyes looking away\",\n",
        "    \"eyes_closed\": \"eyes closed\"\n",
        "}\n",
        "\n",
        "HEADPHONES_OPTIONS = {\n",
        "    \"with_wired\": \"wired headphones\",\n",
        "    \"with_wireless\": \"wireless earbuds\",\n",
        "    \"without\": \"no headphones\"\n",
        "}\n",
        "\n",
        "LOCATION_OPTIONS = {\"indoor\": \"indoor\", \"outdoor\": \"outdoor\"}\n",
        "PRIVACY_OPTIONS = {\"private\": \"alone\", \"public\": \"people behind\"}\n",
        "\n",
        "OBJECT_OPTIONS = {\n",
        "    \"phone\": \"holding phone clearly visible\",\n",
        "    \"pen\": \"holding pen clearly visible\",\n",
        "    \"cup\": \"holding cup clearly visible\",\n",
        "    \"nothing\": \"empty hands clearly visible\",\n",
        "    \"unknown\": \"hands hidden\",\n",
        "    \"other\": \"holding notebook clearly visible\"\n",
        "}"
      ],
      "metadata": {
        "id": "XLPQLGAVRXqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_behavior_vector():\n",
        "    return {\n",
        "        \"gaze\": random.choice(list(GAZE_OPTIONS.keys())),\n",
        "        \"headphones\": random.choice(list(HEADPHONES_OPTIONS.keys())),\n",
        "        \"location\": random.choice(list(LOCATION_OPTIONS.keys())),\n",
        "        \"privacy\": random.choice(list(PRIVACY_OPTIONS.keys())),\n",
        "        \"object\": random.choice(list(OBJECT_OPTIONS.keys()))\n",
        "    }\n",
        "\n",
        "def build_prompt(bv):\n",
        "    prompt = (\n",
        "        \"webcam zoom call, student face, \"\n",
        "        f\"{GAZE_OPTIONS[bv['gaze']]}, \"\n",
        "        f\"{OBJECT_OPTIONS[bv['object']]}, \"\n",
        "        f\"{HEADPHONES_OPTIONS[bv['headphones']]}, \"\n",
        "        f\"{LOCATION_OPTIONS[bv['location']]}, {PRIVACY_OPTIONS[bv['privacy']]}, \"\n",
        "        \"sharp focus, realistic\"\n",
        "    )\n",
        "    negative_prompt = \"blurry eyes, blurry hands, blurry object, cartoon, distorted\"\n",
        "    return prompt, negative_prompt\n",
        "\n",
        "# Show a few prompt examples\n",
        "for _ in range(5):\n",
        "    bv = generate_random_behavior_vector()\n",
        "    p, np = build_prompt(bv)\n",
        "    print(\"Behavior Vector:\", bv)\n",
        "    print(\"Prompt:\", p)\n",
        "    print(\"Negative:\", np)\n",
        "    print(\"-\" * 70)"
      ],
      "metadata": {
        "id": "oabx-PXFRaVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generation loop (optional to run)\n",
        "\n",
        "The following code block performs the full SDXL Turbo generation and writes:\n",
        "- images to `data/synthetic/sdxl_turbo/images/`\n",
        "- labels to `data/synthetic/sdxl_turbo/labels.csv`\n",
        "\n",
        "This is optional to execute for the interim submission (documentation-focused).\n"
      ],
      "metadata": {
        "id": "rAne_mwWRk51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: run full generation (requires GPU + diffusers/torch)\n",
        "# If you do not want to run, keep this cell as documentation.\n",
        "\n",
        "import torch\n",
        "from diffusers import AutoPipelineForText2Image\n",
        "from PIL import Image\n",
        "\n",
        "pipe = AutoPipelineForText2Image.from_pretrained(\n",
        "    \"stabilityai/sdxl-turbo\",\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "rows = []\n",
        "\n",
        "for i in range(NUM_IMAGES_TO_GENERATE):\n",
        "    bv = generate_random_behavior_vector()\n",
        "    prompt, negative_prompt = build_prompt(bv)\n",
        "\n",
        "    seed = random.randint(0, 1_000_000)\n",
        "    generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
        "\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_inference_steps=4,\n",
        "        guidance_scale=0.0,\n",
        "        height=IMAGE_SIZE,\n",
        "        width=IMAGE_SIZE,\n",
        "        generator=generator\n",
        "    ).images[0]\n",
        "\n",
        "    filename = f\"sdxl_{i+1:06d}.jpg\"\n",
        "    image.save(os.path.join(METHOD_A_IMAGES, filename), quality=95)\n",
        "\n",
        "    rows.append({\n",
        "        \"filename\": filename,\n",
        "        \"gaze\": bv[\"gaze\"],\n",
        "        \"headphones\": bv[\"headphones\"],\n",
        "        \"location\": bv[\"location\"],\n",
        "        \"privacy\": bv[\"privacy\"],\n",
        "        \"object\": bv[\"object\"],\n",
        "        \"seed\": seed\n",
        "    })\n",
        "\n",
        "df_a = pd.DataFrame(rows)\n",
        "df_a.to_csv(METHOD_A_LABELS, index=False)\n",
        "df_a.head()"
      ],
      "metadata": {
        "id": "77a5JkQsRjm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Method B: Inpainting Background Replacement\n",
        "\n",
        "Starting from real images (foreground person), we:\n",
        "1. Create a background mask using selfie segmentation.\n",
        "2. Use Stable Diffusion Inpainting to generate a new background.\n",
        "3. Save the resulting image and write metadata to `labels.csv`.\n",
        "\n",
        "We generate backgrounds for four privacy/environment categories:\n",
        "- `pub_ppl`, `priv_no_ppl`, `pub_no_ppl`, `priv_ppl`\n"
      ],
      "metadata": {
        "id": "8RzNSvT4R15W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "METHOD_B_BASE = \"data/synthetic/inpainting_bg_replace\"\n",
        "METHOD_B_IMAGES = os.path.join(METHOD_B_BASE, \"images\")\n",
        "METHOD_B_LABELS = os.path.join(METHOD_B_BASE, \"labels.csv\")\n",
        "\n",
        "os.makedirs(METHOD_B_IMAGES, exist_ok=True)\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)"
      ],
      "metadata": {
        "id": "kBkYyAMYR5Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "\n",
        "def create_background_mask(image_pil: Image.Image) -> Image.Image:\n",
        "    mp_segmentation = mp.solutions.selfie_segmentation\n",
        "    with mp_segmentation.SelfieSegmentation(model_selection=1) as segmenter:\n",
        "        image_cv = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
        "        results = segmenter.process(cv2.cvtColor(image_cv, cv2.COLOR_BGR2RGB))\n",
        "        mask = (results.segmentation_mask < 0.5).astype(np.uint8) * 255\n",
        "        return Image.fromarray(mask)"
      ],
      "metadata": {
        "id": "SvaTp9j1R7Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionInpaintPipeline\n",
        "\n",
        "pipe_inpaint = StableDiffusionInpaintPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-inpainting\",\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "pipe_inpaint.safety_checker = None\n",
        "pipe_inpaint.requires_safety_checker = False\n",
        "\n",
        "public_locs = [\"restaurant\", \"coffee shop\", \"beach\", \"public garden\", \"university hallway\"]\n",
        "private_locs = [\"bedroom\", \"clean home office\", \"living room\", \"minimalist wall background\"]\n",
        "\n",
        "def sample_privacy_category_and_prompt():\n",
        "    category = random.choice([\"pub_ppl\", \"priv_no_ppl\", \"pub_no_ppl\", \"priv_ppl\"])\n",
        "    if category == \"pub_ppl\":\n",
        "        loc = random.choice(public_locs)\n",
        "        prompt = f\"A busy public {loc} background, many people walking behind, blurry crowd, realistic, detailed\"\n",
        "    elif category == \"priv_no_ppl\":\n",
        "        loc = random.choice(private_locs)\n",
        "        prompt = f\"A quiet private {loc} background, empty room, no people, realistic lighting\"\n",
        "    elif category == \"pub_no_ppl\":\n",
        "        loc = random.choice(public_locs)\n",
        "        prompt = f\"An empty public {loc} area, no people present, realistic, high quality\"\n",
        "    else:\n",
        "        loc = random.choice(private_locs)\n",
        "        prompt = f\"A private {loc} at home, blurred family members in background, realistic\"\n",
        "    return category, prompt"
      ],
      "metadata": {
        "id": "onEG8G0_R8mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "rows = []\n",
        "for fname in uploaded.keys():\n",
        "    init_image = Image.open(fname).convert(\"RGB\")\n",
        "\n",
        "    # keep dimensions multiple of 8\n",
        "    w, h = init_image.size\n",
        "    new_w, new_h = (w // 8) * 8, (h // 8) * 8\n",
        "    init_image = init_image.resize((new_w, new_h))\n",
        "\n",
        "    mask_image = create_background_mask(init_image)\n",
        "\n",
        "    category, prompt = sample_privacy_category_and_prompt()\n",
        "\n",
        "    out = pipe_inpaint(\n",
        "        prompt=prompt,\n",
        "        image=init_image,\n",
        "        mask_image=mask_image,\n",
        "        num_inference_steps=35,\n",
        "        guidance_scale=6.5\n",
        "    ).images[0]\n",
        "\n",
        "    out_name = f\"bg_{os.path.splitext(os.path.basename(fname))[0]}_{category}.png\"\n",
        "    out_path = os.path.join(METHOD_B_IMAGES, out_name)\n",
        "    out.save(out_path)\n",
        "\n",
        "    rows.append({\n",
        "        \"source_filename\": fname,\n",
        "        \"output_filename\": out_name,\n",
        "        \"privacy_category\": category,\n",
        "        \"prompt\": prompt\n",
        "    })\n",
        "\n",
        "df_b = pd.DataFrame(rows)\n",
        "df_b.to_csv(METHOD_B_LABELS, index=False)\n",
        "df_b.head()"
      ],
      "metadata": {
        "id": "ZamAh3ndSB3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Notes\n",
        "If you need to download the generated results from Colab, you can zip the output folder (optional)."
      ],
      "metadata": {
        "id": "W1OETKP_SEyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: zip results for download\n",
        "zip_path = \"inpainting_bg_replace_results.zip\"\n",
        "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
        "    for file in os.listdir(METHOD_B_IMAGES):\n",
        "        zipf.write(os.path.join(METHOD_B_IMAGES, file), arcname=file)\n",
        "\n",
        "# from google.colab import files\n",
        "# files.download(zip_path)"
      ],
      "metadata": {
        "id": "MAW5K4HFSGU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "- Method A (SDXL Turbo): generates full synthetic webcam images + behavior-vector labels.\n",
        "- Method B (Inpainting BG replacement): keeps the person, replaces the background, and saves metadata labels."
      ],
      "metadata": {
        "id": "w4Ok-Qr6SJ0j"
      }
    }
  ]
}