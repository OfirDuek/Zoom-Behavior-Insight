# Zoom Behavior Insight

A computer vision project for detecting study-focus signals from Zoom-like webcam frames and producing interpretable outputs:
**gaze**, **headphones**, **background/privacy**, and **object in hand**.

## Repository structure

- **Presentations**: interim milestones and slides  
  - Folder: [`presentations/`](presentations/)
- **Notebooks**: code used for synthetic data creation, EDA, and baseline evaluation  
  - Folder: [`notebooks/`](notebooks/)
- **Documentation**: labeling guidelines and related docs  
  - Folder: [`docs/`](docs/)
- **Sample dataset (for review)**: a small subset of real + synthetic images with labels  
  - Folder: [`data/`](data/)

## Key links

### Presentations
- [`presentations/README.md`](presentations/README.md)

### Notebooks (interim submission)
- [`notebooks/README.md`](notebooks/README.md)
- Data generation: [`notebooks/5_1_data_generation.ipynb`](notebooks/5_1_data_generation.ipynb)
- EDA: [`notebooks/5_2_eda.ipynb`](notebooks/5_2_eda.ipynb)
- Baseline evaluation: [`notebooks/5_3_baseline_evaluation.ipynb`](notebooks/5_3_baseline_evaluation.ipynb)

### Labeling guidelines
- [`docs/README.md`](docs/README.md)
- Guidelines (PDF): [`docs/Labeling_Guidelines.pdf`](docs/Labeling_Guidelines.pdf)

### Data samples
- [`data/README.md`](data/README.md)

## Current status

Work in progress. The interim submission includes:
- synthetic data generation pipeline
- EDA on the labeled dataset
- baseline model training/evaluation and exported metrics/plots
